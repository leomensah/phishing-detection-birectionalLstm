{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "186p2ATFo3Ayp9qQ_fsYJyyG64Io-8Bim",
      "authorship_tag": "ABX9TyOt0a5SGHBJ4XQQHnaM8+mV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leomensah/phishing-detection-birectionalLstm/blob/main/Deep_Learning_for_Phishing_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZR9JJuAl0o4"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "This file gathers data to be used for pre-processing in training and prediction.\n",
        "\"\"\"\n",
        "import pandas as pd\n",
        "\n",
        "blacklist = '/content/drive/MyDrive/AI-Deep-Learning-for-Phishing-URL-Detection-master/phishing_database.csv'\n",
        "whitelist = '/content/drive/MyDrive/AI-Deep-Learning-for-Phishing-URL-Detection-master/whitelist.txt'\n",
        "\n",
        "urls = {}\n",
        "\n",
        "blacklist = pd.read_csv(blacklist)\n",
        "\n",
        "#Assign 0 for non-malicious and 1 as malicious for supervised learning.\n",
        "for url in blacklist['url']:\n",
        "    urls[url] = 1\n",
        "\n",
        "with open(whitelist, 'r') as f:\n",
        "    lines = f.read().splitlines()\n",
        "    for url in lines:\n",
        "        urls[url] = 0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "This file is for training on the PhishTank data.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import load_model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, GRU, Embedding, Dense, Flatten, Bidirectional\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "#from keras.layers.normalization import BatchNormalization\n",
        "import numpy as np\n",
        "\n",
        "# Get and process URL data and labels.\n",
        "\n",
        "samples = []\n",
        "labels = []\n",
        "for k, v in urls.items():\n",
        "    samples.append(k)\n",
        "    labels.append(v)\n",
        "    #print(k, v)\n",
        "    \n",
        "print(labels.count(1))\n",
        "print(labels.count(0))\n",
        "\n",
        "# Preprocess data for training.\n",
        "max_chars = 20000\n",
        "maxlen = 128\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_chars, char_level=True)\n",
        "tokenizer.fit_on_texts(samples)\n",
        "sequences = tokenizer.texts_to_sequences(samples)\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "\n",
        "data = pad_sequences(sequences, maxlen=maxlen)\n",
        "\n",
        "labels = np.asarray(labels)\n",
        "print('Shape of data tensor:', data.shape)\n",
        "print('Shape of label tensor:', labels.shape)\n",
        "\n",
        "# Divide data between training, cross-validation, and test data.\n",
        "training_samples = int(len(samples) * 0.95)\n",
        "validation_samples = int(len(labels) * 0.05)\n",
        "print(training_samples, validation_samples)\n",
        "\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels = labels[indices]\n",
        "'''\n",
        "x = data\n",
        "y = labels\n",
        "'''\n",
        "x = data[:training_samples]\n",
        "y = labels[:training_samples]\n",
        "x_test = data[training_samples: training_samples + validation_samples]\n",
        "y_test = labels[training_samples: training_samples + validation_samples]\n",
        "\n",
        "# Define callbacks for Keras.\n",
        "callbacks_list = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "    filepath='/content/drive/MyDrive/AI-Deep-Learning-for-Phishing-URL-Detection-master/models/lstmchar256256128test.h5',\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True\n",
        "    ),\n",
        "    keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', \n",
        "    min_delta=0,\n",
        "    patience=2, \n",
        "    mode='auto',\n",
        "    baseline=None,\n",
        "    )\n",
        "]\n",
        "\n",
        "num_chars = len(tokenizer.word_index)+1\n",
        "\n",
        "embedding_vector_length = 128\n",
        "\n",
        "# Create model for training.\n",
        "model = Sequential()\n",
        "model.add(Embedding(num_chars, embedding_vector_length, input_length=maxlen))\n",
        "model.add(Bidirectional(LSTM(256, dropout=0.3, recurrent_dropout=0.3, return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(256, dropout=0.3, recurrent_dropout=0.3, return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(128, dropout=0.3, recurrent_dropout=0.3)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "# Train.\n",
        "model.fit(x, y,\n",
        "        epochs=10,\n",
        "        batch_size=200,\n",
        "        callbacks=callbacks_list,\n",
        "        validation_split=0.20,\n",
        "        shuffle=True\n",
        "        )\n",
        "\n",
        "# Evaluate model on test data.\n",
        "score, acc = model.evaluate(x_test, y_test, verbose=1, batch_size=1024)\n",
        "\n",
        "print(\"Model Accuracy: {:0.2f}%\".format(acc * 100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66bQ_0x3mPuS",
        "outputId": "788d08da-e30c-4cad-f923-9ccff824e4d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29769\n",
            "38228\n",
            "Found 69 unique tokens.\n",
            "Shape of data tensor: (67997, 128)\n",
            "Shape of label tensor: (67997,)\n",
            "64597 3399\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 128, 128)          8960      \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirectio  (None, 128, 512)         788480    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " bidirectional_4 (Bidirectio  (None, 128, 512)         1574912   \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " bidirectional_5 (Bidirectio  (None, 256)              656384    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,028,993\n",
            "Trainable params: 3,028,993\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "259/259 [==============================] - 590s 2s/step - loss: 0.3341 - accuracy: 0.8555 - val_loss: 0.1810 - val_accuracy: 0.9380\n",
            "Epoch 2/10\n",
            "259/259 [==============================] - 577s 2s/step - loss: 0.1485 - accuracy: 0.9494 - val_loss: 0.0996 - val_accuracy: 0.9682\n",
            "Epoch 3/10\n",
            "259/259 [==============================] - 578s 2s/step - loss: 0.0963 - accuracy: 0.9690 - val_loss: 0.0623 - val_accuracy: 0.9796\n",
            "Epoch 4/10\n",
            "259/259 [==============================] - 580s 2s/step - loss: 0.0632 - accuracy: 0.9801 - val_loss: 0.0412 - val_accuracy: 0.9885\n",
            "Epoch 5/10\n",
            "259/259 [==============================] - 583s 2s/step - loss: 0.0512 - accuracy: 0.9850 - val_loss: 0.0368 - val_accuracy: 0.9890\n",
            "Epoch 6/10\n",
            "259/259 [==============================] - 583s 2s/step - loss: 0.0449 - accuracy: 0.9860 - val_loss: 0.0336 - val_accuracy: 0.9891\n",
            "Epoch 7/10\n",
            "259/259 [==============================] - 584s 2s/step - loss: 0.0310 - accuracy: 0.9900 - val_loss: 0.0198 - val_accuracy: 0.9936\n",
            "Epoch 8/10\n",
            "259/259 [==============================] - 584s 2s/step - loss: 0.0272 - accuracy: 0.9909 - val_loss: 0.0263 - val_accuracy: 0.9923\n",
            "Epoch 9/10\n",
            "259/259 [==============================] - 584s 2s/step - loss: 0.0236 - accuracy: 0.9924 - val_loss: 0.0171 - val_accuracy: 0.9947\n",
            "Epoch 10/10\n",
            "259/259 [==============================] - 585s 2s/step - loss: 0.0179 - accuracy: 0.9942 - val_loss: 0.0155 - val_accuracy: 0.9950\n",
            "4/4 [==============================] - 1s 278ms/step - loss: 0.0159 - accuracy: 0.9944\n",
            "Model Accuracy: 99.44%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "This file is for training on the PhishTank data.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import load_model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, GRU, Embedding, Dense, Flatten, Bidirectional\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "#from keras.layers.normalization import BatchNormalization\n",
        "import numpy as np\n",
        "\n",
        "# Get and process URL data and labels.\n",
        "\n",
        "samples = []\n",
        "labels = []\n",
        "for k, v in urls.items():\n",
        "    samples.append(k)\n",
        "    labels.append(v)\n",
        "    #print(k, v)\n",
        "    \n",
        "print(labels.count(1))\n",
        "print(labels.count(0))\n",
        "\n",
        "# Preprocess data for training.\n",
        "max_chars = 20000\n",
        "maxlen = 128\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_chars, char_level=True)\n",
        "tokenizer.fit_on_texts(samples)\n",
        "sequences = tokenizer.texts_to_sequences(samples)\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "\n",
        "data = pad_sequences(sequences, maxlen=maxlen)\n",
        "\n",
        "labels = np.asarray(labels)\n",
        "print('Shape of data tensor:', data.shape)\n",
        "print('Shape of label tensor:', labels.shape)\n",
        "\n",
        "# Divide data between training, cross-validation, and test data.\n",
        "training_samples = int(len(samples) * 0.95)\n",
        "validation_samples = int(len(labels) * 0.05)\n",
        "print(training_samples, validation_samples)\n",
        "\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels = labels[indices]\n",
        "'''\n",
        "x = data\n",
        "y = labels\n",
        "'''\n",
        "x = data[:training_samples]\n",
        "y = labels[:training_samples]\n",
        "x_test = data[training_samples: training_samples + validation_samples]\n",
        "y_test = labels[training_samples: training_samples + validation_samples]\n",
        "\n",
        "# Define callbacks for Keras.\n",
        "callbacks_list = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "    filepath='/content/drive/MyDrive/AI-Deep-Learning-for-Phishing-URL-Detection-master/models/lstmchar256256128test.h5',\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True\n",
        "    ),\n",
        "    keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', \n",
        "    min_delta=0,\n",
        "    patience=2, \n",
        "    mode='auto',\n",
        "    baseline=None,\n",
        "    )\n",
        "]\n",
        "\n",
        "num_chars = len(tokenizer.word_index)+1\n",
        "\n",
        "embedding_vector_length = 128\n",
        "\n",
        "# Create model for training.\n",
        "model = Sequential()\n",
        "model.add(Embedding(num_chars, embedding_vector_length, input_length=maxlen))\n",
        "model.add(Bidirectional(LSTM(256, dropout=0.3, recurrent_dropout=0.3, return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(256, dropout=0.3, recurrent_dropout=0.3, return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(128, dropout=0.3, recurrent_dropout=0.3)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "# Train.\n",
        "model.fit(x, y,\n",
        "        epochs=30,\n",
        "        batch_size=200,\n",
        "        callbacks=callbacks_list,\n",
        "        validation_split=0.20,\n",
        "        shuffle=True\n",
        "        )\n",
        "\n",
        "# Evaluate model on test data.\n",
        "score, acc = model.evaluate(x_test, y_test, verbose=1, batch_size=1024)\n",
        "\n",
        "print(\"Model Accuracy: {:0.2f}%\".format(acc * 100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ussue5xMoO9",
        "outputId": "7820fcc8-b7fc-4db7-fc3d-dd4de012c367"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29769\n",
            "38228\n",
            "Found 69 unique tokens.\n",
            "Shape of data tensor: (67997, 128)\n",
            "Shape of label tensor: (67997,)\n",
            "64597 3399\n",
            "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 128, 128)          8960      \n",
            "                                                                 \n",
            " bidirectional_6 (Bidirectio  (None, 128, 512)         788480    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " bidirectional_7 (Bidirectio  (None, 128, 512)         1574912   \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " bidirectional_8 (Bidirectio  (None, 256)              656384    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,028,993\n",
            "Trainable params: 3,028,993\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "259/259 [==============================] - 593s 2s/step - loss: 0.2710 - accuracy: 0.8858 - val_loss: 0.1297 - val_accuracy: 0.9560\n",
            "Epoch 2/30\n",
            "259/259 [==============================] - 581s 2s/step - loss: 0.1109 - accuracy: 0.9627 - val_loss: 0.0621 - val_accuracy: 0.9810\n",
            "Epoch 3/30\n",
            "259/259 [==============================] - 582s 2s/step - loss: 0.0693 - accuracy: 0.9785 - val_loss: 0.0556 - val_accuracy: 0.9825\n",
            "Epoch 4/30\n",
            "259/259 [==============================] - 585s 2s/step - loss: 0.0567 - accuracy: 0.9824 - val_loss: 0.0385 - val_accuracy: 0.9878\n",
            "Epoch 5/30\n",
            "259/259 [==============================] - 586s 2s/step - loss: 0.0409 - accuracy: 0.9874 - val_loss: 0.0284 - val_accuracy: 0.9906\n",
            "Epoch 6/30\n",
            "259/259 [==============================] - 586s 2s/step - loss: 0.0264 - accuracy: 0.9915 - val_loss: 0.0287 - val_accuracy: 0.9908\n",
            "Epoch 7/30\n",
            "259/259 [==============================] - 587s 2s/step - loss: 0.0290 - accuracy: 0.9909 - val_loss: 0.0291 - val_accuracy: 0.9896\n",
            "4/4 [==============================] - 1s 276ms/step - loss: 0.0191 - accuracy: 0.9929\n",
            "Model Accuracy: 99.29%\n"
          ]
        }
      ]
    }
  ]
}